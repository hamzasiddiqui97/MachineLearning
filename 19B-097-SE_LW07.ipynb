{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Baseline Models and Voting<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from numpy import mean\n", "from numpy import std\n", "from sklearn.datasets import make_classification\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.model_selection import RepeatedStratifiedKFold\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.naive_bayes import GaussianNB\n", "from matplotlib import pyplot\n", "# get the dataset\n", "def get_dataset () :\n", "    X , y = make_classification(n_samples=5000,n_features=20,n_informative=10 , n_redundant =10 , random_state =1)\n", "    return X,y\n", "def get_models () :\n", "    models = list ()\n", "    models.append (('lr', LogisticRegression ()))\n", "    models.append (('knn', KNeighborsClassifier()))\n", "    models.append (('tree', DecisionTreeClassifier()))\n", "    models.append (('nb', GaussianNB()))\n", "    models.append (('svm', SVC ( probability = True)))\n", "    return models\n", "def evaluate_model (model ,X ,y) :\n", "    cv = RepeatedStratifiedKFold (n_splits=10,n_repeats=3 , random_state =1)\n", "    scores = cross_val_score(model,X,y,scoring ='accuracy',cv= cv , n_jobs= -1)\n", "    return scores\n", "X , y = get_dataset ()\n", "models = get_models ()\n", "results,names = list () , list ()\n", "for name,model in models :\n", "    scores = evaluate_model ( model , X , y )\n", "    # store results\n", "    results.append ( scores )\n", "    names.append ( name )\n", "    print (' >%s %.3f (%.3f)' % ( name,mean(scores ) , std(scores)))\n", "pyplot.boxplot(results,labels = names , showmeans = True )\n", "pyplot.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.ensemble import VotingClassifier\n", "ensemble = VotingClassifier ( estimators = models , voting ='soft')\n", "# define the evaluation procedure\n", "cv = RepeatedStratifiedKFold ( n_splits=10,n_repeats =3 , random_state =1)\n", "# evaluate the ensemble\n", "scores = cross_val_score ( ensemble,X,y,scoring ='accuracy', cv = cv , n_jobs\n", "= -1)\n", "# summarize the result\n", "print ('Mean Accuracy : %.3f (%.3f)' % ( mean(scores),std(scores)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["evaluate a list of models"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate_ensemble ( models,X,y):\n", "    # check for no models\n", "    if len(models) == 0:\n", "        return 0.0\n", "    # create the ensemble\n", "    ensemble = VotingClassifier ( estimators = models , voting ='soft')\n", "    # define the evaluation procedure\n", "    cv = RepeatedStratifiedKFold ( n_splits =10 , n_repeats =3 , random_state =1)\n", "    # evaluate the ensemble\n", "    scores = cross_val_score (ensemble, X,y , scoring ='accuracy',cv=cv ,n_jobs=-1)\n", "    # return mean score\n", "    return mean ( scores )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["perform a single round of pruning the ensemble"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def prune_round (models_in ,X,y) :\n", "    # establish a baseline\n", "    baseline = evaluate_ensemble (models_in , X , y )\n", "    best_score , removed = baseline , None\n", "    # enumerate removing each candidate and see if we can improve performance\n", "    for m in models_in:\n", "        # copy the list of chosen models\n", "        dup = models_in.copy ()\n", "        # remove this model\n", "        dup.remove (m)\n", "        # evaluate new ensemble\n", "        result = evaluate_ensemble (dup,X ,y)\n", "        # check for new best\n", "        if result > best_score :\n", "            # store the new best\n", "            best_score,removed = result , m\n", "    return best_score , removed"]}, {"cell_type": "markdown", "metadata": {}, "source": ["prune an ensemble from scratch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def prune_ensemble (models , X , y ) :\n", "    best_score = 0.0\n", "    # prune ensemble until no further improvement\n", "    while True :\n", "        # remove one model to the ensemble\n", "        score , removed = prune_round ( models , X , y )\n", "        # check for no improvement\n", "        if removed is None :\n", "            print ('>no further improvement')\n", "            break\n", "        # keep track of best score\n", "        best_score = score\n", "        # remove model from the list\n", "        models . remove ( removed )\n", "        # report results along the way\n", "        print ('>%.3f ( removed : %s)' % ( score , removed [0]) )\n", "    return best_score , models"]}, {"cell_type": "markdown", "metadata": {}, "source": ["define dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X , y = get_dataset ()\n", "# get the models to evaluate\n", "models = get_models ()\n", "# prune the ensemble\n", "score , model_list = prune_ensemble ( models , X , y )\n", "names = ','. join ([ n for n , _ in model_list ])\n", "print ('Models : %s' % names )\n", "print ('Final Mean Accuracy : %.3f' % score )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Ensemble Growing Example:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate_ensemble ( models , X , y ) :\n", "    # check for no models\n", "    if len( models ) == 0:\n", "        return 0.0\n", "    # create the ensemble\n", "    ensemble = VotingClassifier ( estimators = models , voting ='soft')\n", "    # define the evaluation procedure\n", "    cv = RepeatedStratifiedKFold ( n_splits =10 , n_repeats =3 , random_state =1)\n", "    # evaluate the ensemble\n", "    scores = cross_val_score ( ensemble , X , y , scoring ='accuracy', cv = cv , n_jobs= -1)\n", "    # return mean score\n", "    return mean ( scores )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["perform a single round of pruning the ensemble"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def grow_round ( models_in , models_candidate , X , y ) :\n", "    baseline = evaluate_ensemble(models_in , X , y )\n", "    best_score,addition = baseline,None\n", "    # enumerate adding each candidate and see if we can improve performance\n", "    for m in models_candidate:\n", "    # copy the list of chosen models\n", "        dup = models_in.copy()\n", "        # add the candidate\n", "        dup.append(m)\n", "    # evaluate new ensemble\n", "        result = evaluate_ensemble(dup,X,y)\n", "        # check for new best\n", "        if result > best_score :\n", "    # store the new best\n", "            best_score,addition = result , m\n", "    return best_score , addition"]}, {"cell_type": "markdown", "metadata": {}, "source": ["prune an ensemble from scratch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def grow_ensemble ( models , X , y ) :\n", "    best_score , best_list = 0.0 , list ()\n", "# grow ensemble until no further improvement\n", "    while True :\n", "    # add one model to the ensemble\n", "        score , addition = grow_round ( best_list , models , X , y )\n", "        # check for no improvement\n", "        if addition is None :\n", "            print ('>no further improvement')\n", "            break\n", "        # keep track of best score\n", "        best_score = score\n", "        # remove new model from the list of candidates\n", "        models . remove ( addition )\n", "        # add new model to the list of models in the ensemble\n", "        best_list . append ( addition )\n", "        # report results along the way\n", "        names = ','. join ([ n for n , _ in best_list ])\n", "        print ('>%.3f (%s)'%( score , names ) )\n", "    return best_score , best_list"]}, {"cell_type": "markdown", "metadata": {}, "source": ["define dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X , y = get_dataset ()\n", "# get the models to evaluate\n", "models = get_models ()\n", "# prune the ensemble\n", "score , model_list = grow_ensemble ( models , X , y)\n", "names = ','. join ([ n for n , _ in model_list ])\n", "print ('Models : %s' % names )\n", "print ('Final Mean Accuracy : %.3f' % score )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from numpy import mean\n", "from numpy import std\n", "from pandas import \n", "from sklearn.datasets import load_diabetes\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.model_selection import RepeatedStratifiedKFold\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.naive_bayes import GaussianNB\n", "from matplotlib import pyplot"]}, {"cell_type": "markdown", "metadata": {}, "source": ["get the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_dataset () :\n", "    X , y = load_diabetes(return_X_y=True, as_frame=True)\n", "    return X,y\n", "def get_models () :\n", "    models = list ()\n", "    models . append (( 'lr', LogisticRegression () ) )\n", "    models . append (( 'knn', KNeighborsClassifier () ) )\n", "    models . append (( 'tree', DecisionTreeClassifier () ) )\n", "    models . append (( 'nb', GaussianNB () ) )\n", "    models . append (( 'svm', SVC ( probability = True ) ) )\n", "    return models\n", "def evaluate_model ( model , X , y ) :\n", "    cv = RepeatedStratifiedKFold (n_splits=6,n_repeats=3 , random_state =1)\n", "    scores = cross_val_score(model,X,y,scoring ='accuracy',cv= cv , n_jobs= -1)\n", "    return scores\n", "X , y = get_dataset ()\n", "models = get_models ()\n", "results,names = list () , list ()\n", "for name,model in models :\n", "    scores = evaluate_model ( model , X , y )\n", "    # store results\n", "    results.append ( scores )\n", "    names.append ( name )\n", "    print (' >%s %.3f (%.3f)' % ( name,mean(scores ) , std(scores)))\n", "pyplot.boxplot(results,labels = names , showmeans = True )\n", "pyplot.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}