{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[12]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.datasets import load_iris\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn . neighbors import KNeighborsClassifier\n", "X , Y = load_iris(return_X_y=True)\n", "X_train , X_test , y_train , y_test = train_test_split (X , Y , test_size = 0.2,random_state =32)\n", "sc = StandardScaler ()\n", "sc . fit ( X_train )\n", "X_train = sc . transform ( X_train )\n", "sc . fit ( X_test )\n", "X_test = sc . transform ( X_test )\n", "X . shape\n", "# Step 2\n", "error1 = []\n", "error2 = []\n", "for k in range (1 ,15) :\n", "    knn = KNeighborsClassifier ( n_neighbors = k )\n", "    knn . fit ( X_train , y_train )\n", "    y_pred1 = knn . predict ( X_train )\n", "    error1 . append ( np . mean ( y_train != y_pred1 ) )\n", "    y_pred2 = knn . predict ( X_test )\n", "    error2 . append ( np . mean ( y_test != y_pred2 ) )\n", "# plt . figure ( figsize (10 ,5))\n", "plt . plot ( range (1 ,15) , error1 , label =\"train\")\n", "plt . plot ( range (1 ,15) , error2 , label =\"test\")\n", "plt . xlabel ('k Value ')\n", "plt . ylabel ('Error')\n", "plt . legend ()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import metrics\n", "knn = KNeighborsClassifier ( n_neighbors =7)\n", "knn . fit ( X_train , y_train )\n", "y_pred = knn . predict ( X_test )\n", "metrics . accuracy_score ( y_test , y_pred )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('Surgical-deepnet.csv')\n", "y_pred=np.array([0,0,1,1,0,0,0,1,0,0])\n", "y_true = df[['baseline_cvd','baseline_dementia','baseline_diabetes','baseline_digestive','baseline_osteoart','baseline_psych','baseline_pulmonary','gender','mort30','complication']]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn . metrics import jaccard_score , confusion_matrix\n", "for i in range (10) :\n", "    print ( jaccard_score(y_true.iloc[i,:],y_pred))\n", "    print ( confusion_matrix(y_true.iloc[10,:],y_pred,labels =[0 ,1]) )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Cosine"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[12]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["doc_trump = \"Mr. Trump became president after winning the political election.Though he lost the support of some republican friends , Trump isfriends with President Putin\"\n", "doc_election = \" President Trump says Putin had no political interference isthe election outcome.He says it was a witchhunt by political parties.He claimed President Putin is a friend who had nothing to do with theelection\"\n", "doc_putin = \" Post elections , Vladimir Putin became President of Russia.President Putin had served as the Prime Minister earlier in hispolitical career \"\n", "documents = [ doc_trump , doc_election , doc_putin ]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[13]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn . feature_extraction . text import CountVectorizer\n", "from sklearn . metrics . pairwise import cosine_similarity\n", "import pandas as pd\n", "# Create the Document Term Matrix\n", "count_vectorizer = CountVectorizer(stop_words='english')\n", "count_vectorizer = CountVectorizer ()\n", "sparse_matrix = count_vectorizer . fit_transform ( documents )\n", "# OPTIONAL : Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies .\n", "doc_term_matrix = sparse_matrix.todense ()\n", "count_vectorizer.get_feature_names\n", "df = pd.DataFrame ( doc_term_matrix ,\n", "columns = count_vectorizer.get_feature_names(),index =['doc_trump','doc_election','doc_putin'])\n", "print(cosine_similarity ( df , df ) )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Mahalanobis Distance"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[8]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from scipy import linalg\n", "import numpy as np\n", "data = pd . read_csv ('diamonds.csv')\n", "df = pd . DataFrame ( data ).iloc [: , [0 ,4 ,6]]\n", "def mahalanobis( x = None,data = None , cov = None ) :\n", "    x_minus_mu= x-np.mean ( data , axis =0)\n", "    if not cov:\n", "        cov = np . cov ( data .values . T )\n", "        inv_covmat = linalg.inv ( cov )\n", "        left_term = np . dot ( x_minus_mu , inv_covmat )\n", "        mahal = np . dot ( left_term , x_minus_mu . T )\n", "    return mahal . diagonal ()\n", "df_x = df [[ 'carat', 'depth', 'price']]. head (500)\n", "df_x ['mahala'] = mahalanobis ( x = df_x , data = df [['carat', 'depth', 'price']])\n", "df_x . head ()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Multivariate outlier detection using Mahalanobis distance"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[9]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy . stats import chi2\n", "chi2 . ppf ((1 -0.01) , df =2)\n", "# Compute the P- Values\n", "df_x ['p_value'] = 1 - chi2 . cdf ( df_x ['mahala'] , 2)\n", "# Extreme values with a significance level of 0.01\n", "df_x .loc [df_x . p_value < 0.01]. head (10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# KD Tree"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[11]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from sklearn.neighbors import KDTree\n", "data = pd .read_csv ('Agility_Speed.csv')\n", "df =pd.DataFrame ( data )\n", "x =df['Speed']\n", "y =df['Agility']\n", "X = df[['Speed','Agility']]\n", "tree= KDTree(X,leaf_size=2)\n", "dist,ind = tree . query ([[6 ,3.5]] , k =2)\n", "print(ind)\n", "print(dist)\n", "plt. scatter(x,y , color ='red', marker ='o')\n", "plt.scatter(6,3.5 , color ='blue',marker ='v')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# LAB TASK"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ASK NO 1:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[18]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn . neighbors import KNeighborsClassifier\n", "label_encoder = LabelEncoder()\n", "df = pd.read_csv('heart.csv')\n", "df['Sex']= label_encoder.fit_transform(df['Sex'])\n", "df['ChestPainType']= label_encoder.fit_transform(df['ChestPainType'])\n", "df['RestingECG']= label_encoder.fit_transform(df['RestingECG'])\n", "df['ExerciseAngina']= label_encoder.fit_transform(df['ExerciseAngina'])\n", "df['ST_Slope']= label_encoder.fit_transform(df['ST_Slope'])\n", "X = df.drop('HeartDisease',axis=1)\n", "Y = df['HeartDisease']\n", "X_train , X_test , y_train , y_test = train_test_split (X , Y , test_size = 0.2,random_state =32)\n", "sc = StandardScaler ()\n", "sc . fit ( X_train )\n", "X_train = sc . transform ( X_train )\n", "sc . fit ( X_test )\n", "X_test = sc . transform ( X_test )\n", "X . shape\n", "# Step 2\n", "error1 = []\n", "error2 = []\n", "for k in range (1 ,15) :\n", "    knn = KNeighborsClassifier ( n_neighbors = k )\n", "    knn . fit ( X_train , y_train )\n", "    y_pred1 = knn . predict ( X_train )\n", "    error1 . append ( np . mean ( y_train != y_pred1 ) )\n", "    y_pred2 = knn . predict ( X_test )\n", "    error2 . append ( np . mean ( y_test != y_pred2 ) )\n", "# plt . figure ( figsize (10 ,5))\n", "plt . plot ( range (1 ,15) , error1 , label =\"train\")\n", "plt . plot ( range (1 ,15) , error2 , label =\"test\")\n", "plt . xlabel ('k Value ')\n", "plt . ylabel ('Error')\n", "plt . legend ()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ASK NO 2:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from sklearn . feature_extraction . text import CountVectorizer\n", "from sklearn . metrics . pairwise import cosine_similarity\n", "import pandas as pd\n", "df = pd.read_csv('IMDBdata_MainData.csv')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["features = ['Genre', 'Plot', 'Language']\n", "for feature in features:\n", "    df[feature] = df[feature].fillna('')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def combined_features(row):\n", "    return row['Genre']+\" \"+row['Plot']+\" \"+row['Language']\n", "df[\"combined_features\"] = df.apply(combined_features, axis =1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cv = CountVectorizer()\n", "count_matrix = cv.fit_transform(df[\"combined_features\"])\n", "count_matrix.toarray()\n", "cosine_sim = cosine_similarity(count_matrix)\n", "print(cosine_sim)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ASK NO 3:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from scipy import linalg\n", "import numpy as np\n", "data = pd . read_csv ('diabetes.csv')\n", "df = pd . DataFrame ( data )\n", "def mahalanobis( x = None,data = None , cov = None ) :\n", "    x_minus_mu= x-np.mean ( data , axis =0)\n", "    if not cov:\n", "        cov = np . cov ( data .values . T )\n", "        inv_covmat = linalg.inv ( cov )\n", "        left_term = np . dot ( x_minus_mu , inv_covmat )\n", "        mahal = np . dot ( left_term , x_minus_mu . T )\n", "    return mahal . diagonal ()\n", "df_x = df [['Pregnancies','Glucose', 'BloodPressure','SkinThickness','Insulin', 'BMI','DiabetesPedigreeFunction','Age','Outcome']]. head (500)\n", "df_x ['mahala'] = mahalanobis ( x = df_x , data = df [['Pregnancies','Glucose', 'BloodPressure','SkinThickness','Insulin', 'BMI','DiabetesPedigreeFunction','Age','Outcome']])\n", "df_x.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy . stats import chi2\n", "chi2 . ppf ((1 -0.05) , df =2)\n", "df_x ['p_value'] = 1 - chi2 . cdf ( df_x ['mahala'] , 2)\n", "df_x .loc [df_x . p_value < 0.05]. head (10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ASK NO 4:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[14]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.neighbors import KDTree\n", "import matplotlib.pyplot as plt\n", "data = pd .read_csv ('Agility_Speed.csv')\n", "df =pd.DataFrame ( data )\n", "x =df['Speed']\n", "y =df['Agility']\n", "X = list (zip(x , y ) )\n", "tree= KDTree(X,leaf_size=2)\n", "dist,ind = tree . query ([[6 ,3.5]] , k =2)\n", "print(ind)\n", "print(dist)\n", "plt. scatter(x,y , color ='red', marker ='o')\n", "plt.scatter(6,3.5 , color ='blue',marker ='v')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ASK NO 5:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from sklearn.neighbors import KDTree\n", "from sklearn.preprocessing import StandardScaler"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class KDTree:\n\n", "    # class initialization function\n", "    def __init__(self, data, mins, maxs):\n", "        self.data = np.asarray(data)\n\n", "        # data should be two-dimensional\n", "        assert self.data.shape[1] == 2\n", "        if mins is None:\n", "            mins = data.min(0)\n", "        if maxs is None:\n", "            maxs = data.max(0)\n", "        self.mins = np.asarray(mins)\n", "        self.maxs = np.asarray(maxs)\n", "        self.sizes = self.maxs - self.mins\n", "        self.child1 = None\n", "        self.child2 = None\n", "        if len(data) > 1:\n", "            # sort on the dimension with the largest spread\n", "            largest_dim = np.argmax(self.sizes)\n", "            i_sort = np.argsort(self.data[:, largest_dim])\n", "            self.data[:] = self.data[i_sort, :]\n\n", "            # find split point\n", "            N = self.data.shape[0]\n", "            half_N = int(N / 2)\n", "            split_point = 0.5 * (self.data[half_N, largest_dim]\n", "                                 + self.data[half_N - 1, largest_dim])\n\n", "            # create subnodes\n", "            mins1 = self.mins.copy()\n", "            mins1[largest_dim] = split_point\n", "            maxs2 = self.maxs.copy()\n", "            maxs2[largest_dim] = split_point\n\n", "            # Recursively build a KD-tree on each sub-node\n", "            self.child1 = KDTree(self.data[half_N:], mins1, self.maxs)\n", "            self.child2 = KDTree(self.data[:half_N], self.mins, maxs2)\n", "    def draw_rectangle(self, ax, depth=None):\n", "       \n", "        if depth == 0:\n", "            rect = plt.Rectangle(self.mins, *self.sizes, ec='k', fc='none')\n", "            ax.add_patch(rect)\n", "        if self.child1 is not None:\n", "            if depth is None:\n", "                self.child1.draw_rectangle(ax)\n", "                self.child2.draw_rectangle(ax)\n", "            elif depth > 0:\n", "                self.child1.draw_rectangle(ax, depth - 1)\n", "                self.child2.draw_rectangle(ax, depth - 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = pd.DataFrame(df[['Speed','Agility']]).to_numpy()\n", "scaler = StandardScaler()\n", "X = scaler.fit_transform(X)\n", "X[:, 1] *= 0.1\n", "X[:, 1] += X[:, 0] ** 2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["KDT = KDTree(X, [-1.1, -0.1], [1.1, 1.1])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(10, 10))\n", "fig.subplots_adjust(wspace=0.1, hspace=0.15,\n", "                    left=0.1, right=0.9,\n", "                    bottom=0.05, top=0.9)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for level in range(1, 5):\n", "    ax = fig.add_subplot(2, 2, level, xticks=[], yticks=[])\n", "    ax.scatter(X[:, 0], X[:, 1], s=9)\n", "    KDT.draw_rectangle(ax, depth=level - 1)\n", "    ax.set_xlim(-1.2, 1.2)\n", "    ax.set_ylim(-0.15, 1.15)\n", "    ax.set_title('level %i' % level)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["suptitle() adds a title to the entire figure"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig.suptitle('KD-tree')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}