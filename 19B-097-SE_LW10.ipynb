{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Naive Bayes Categorical data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[1]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class NBClassifier :\n", "    def __init__ ( self , data , target ) :\n", "        self . data = data\n", "        self . target = target\n", "        self.prob_all= list()\n", "        self.tprob_dict = dict()\n", "        \n", "        \n", "    def target_prob ( self ) :\n", "        class_list = self.data.loc[:,self.target].unique()\n", "        total_rows = self.data.shape[0]\n", "        \n", "        for c in class_list : # for each class in the label\n", "            total_class_count = self . data [ self . data [ self . target ] == c ].shape [0] # number of the class\n", "            self . tprob_dict [ c ]= total_class_count / total_rows\n", "        return self . tprob_dict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def cond_prob(self ,feature ) :\n", "        feature_class_list=self.data.loc[:,feature].unique()\n", "        target_class_list= self.data.loc[:,self.target].unique()\n", "        total_rows=self.data.shape[0]\n", "        cond_prob_list=list()\n", "        counter =0\n", "        for t_level in target_class_list :\n", "            t_level_count = self . data [ self . data [ self . target ] == t_level ].shape [0]\n", "            for f_level in feature_class_list :\n", "                counter =0\n", "                for i in range ( total_rows ) :\n", "                    if ( self . data . loc [i , feature ] == f_level ) and ( self . data .loc [i , self . target ] == t_level ):\n", "                        counter +=1\n", "                cond_prob_list . append (( feature , f_level , t_level , round ( counter/ t_level_count ,3) ) )\n", "        return cond_prob_list\n", "    \n", "    def cond_prob_LPSmoother ( self , feature , k ) :\n", "        feature_class_list = self.data.loc[:,feature].unique()\n", "        target_class_list = self.data.loc[:,self.target].unique()\n", "        total_rows = self.data.shape[0]\n", "        counter = 0\n", "        cond_prob_list = list()\n", "        f_level_count =len (feature_class_list)\n", "        for t_level in target_class_list :\n", "            t_level_count = self . data [ self . data [ self . target ] == t_level ].shape [0]\n", "            for f_level in feature_class_list :\n", "                counter =0\n", "                for i in range ( total_rows ) :\n", "                    if ( self . data . loc [i , feature ] == f_level ) and ( self . data .loc [i , self . target ] == t_level ) :\n", "                        counter +=1\n", "                cp_smoother = ( counter + k ) /( t_level_count +( k * f_level_count ))\n", "                cond_prob_list . append (( feature , f_level , t_level , round (cp_smoother ,3) ) )\n", "        return cond_prob_list\n", "    \n", "    def count_all_prob ( self , k = None ) :\n", "        X=self.data.drop([self.target],axis=1)\n", "        if k!=None:\n", "            for feature in X.columns :\n", "                cond_list = self . cond_prob_LPSmoother(feature,k)\n", "                self.prob_all = self . prob_all + cond_list\n", "        else:\n", "            for feature in X.columns :\n", "                cond_list = self . cond_prob(feature)\n", "                self.prob_all = self . prob_all + cond_list\n", "            \n", "        return self.prob_all\n", "    def fit (self,smoothing='LPS',k=None) :\n", "        self.target_prob()\n", "        if smoothing == 'LPS' and k!=None:\n", "            self . count_all_prob (k)\n", "        else:\n", "            self . count_all_prob ()\n", "        return None\n", "    def pred_score ( self , query ) :\n", "        num_of_arg=self.data.shape[1]-1\n", "        query_length=len(query)\n", "        prob_dict=dict()\n", "        prob_prod=1\n", "        feature_list=self.data.columns\n", "        if query_length != num_of_arg :\n", "            print ('Query required ', num_of_arg ,' number of arguments')\n", "            print ('Data set column ', self.data.columns )\n", "        else :\n", "            i =0\n", "            for item in query :\n", "                if item not in self . data . iloc [: , i ]. unique () :\n", "                    print ( item ,'is not in coulmn ', self . data . columns [ i ])\n", "                i +=1\n", "            for t_level in self . data [ self . target ]. unique () :\n", "                for cnt in range ( query_length ) :\n", "                    for item in self . prob_all :\n", "                        if item [0]== feature_list [cnt] and item [1]== query [cnt] and item [2]== t_level :\n", "                            prob_prod = prob_prod * item [3]\n", "                prob_dict [ t_level ]= round ( prob_prod * self . tprob_dict [ t_level] ,4)\n", "                prob_prod = 1\n", "        return prob_dict\n", "    \n", "    def pred ( self , query ) :\n", "        pr_dict = self . pred_score ( query )\n", "        return max( pr_dict , key = pr_dict . get )\n", "    \n", "    def get_prob_dict ( self ) :\n", "        print ('Target probabilities : ', self . tprob_dict )\n", "        print ('Conditional features Probabilities : ', self . prob_all )\n", "        return None\n", "    \n", "    \n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[2]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "data = pd . read_csv ('LoanApplication_cat.csv', sep =',')\n", "df = pd . DataFrame ( data )\n", "df = df.drop(['ID'],axis=1)\n", "nbc = NBClassifier ( df ,'Fraud')\n", "nbc . fit ()\n", "query = ['paid','none','rent']\n", "nbc . pred_score ( query )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[3]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nbc . get_prob_dict ()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[4]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nbc = NBClassifier ( df ,'Fraud')\n", "nbc . fit ( smoothing ='LPS',k =3)\n", "query = ['paid','guarantor','free']\n", "nbc . pred_score ( query )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[5]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nbc.pred(query)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[6]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nbc.get_prob_dict()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# CONTINUOUS DATA"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[7]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class NBClassifier :\n", "    def __init__ ( self , data , target,bins ) :\n", "        self . data = data\n", "        self . target = target\n", "        self.prob_all= list()\n", "        self.tprob_dict = dict()\n", "        self.bins = bins\n", "        \n", "        \n", "    def target_prob ( self ) :\n", "        class_list = self.data.loc[:,self.target].unique()\n", "        total_rows = self.data.shape[0]\n", "        \n", "        for c in class_list : # for each class in the label\n", "            total_class_count = self . data [ self . data [ self . target ] == c ].shape [0] # number of the class\n", "            self . tprob_dict [ c ]= total_class_count / total_rows\n", "        return self . tprob_dict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    def cond_prob(self ,feature ) :\n", "        feature_class_list=self.data.loc[:,feature].unique()\n", "        target_class_list= self.data.loc[:,self.target].unique()\n", "        total_rows=self.data.shape[0]\n", "        cond_prob_list=list()\n", "        counter =0\n", "        for t_level in target_class_list :\n", "            t_level_count = self . data [ self . data [ self . target ] == t_level ].shape [0]\n", "            for f_level in feature_class_list :\n", "                counter =0\n", "                for i in range ( total_rows ) :\n", "                    if ( self . data . loc [i , feature ] == f_level ) and ( self . data .loc [i , self . target ] == t_level ):\n", "                        counter +=1\n", "                cond_prob_list . append (( feature , f_level , t_level , round ( counter/ t_level_count ,3) ) )\n", "        return cond_prob_list\n", "    \n", "    def cond_prob_LPSmoother ( self , feature , k ) :\n", "        feature_class_list = self.data.loc[:,feature].unique()\n", "        target_class_list = self.data.loc[:,self.target].unique()\n", "        total_rows = self.data.shape[0]\n", "        counter = 0\n", "        cond_prob_list = list()\n", "        f_level_count =len (feature_class_list)\n", "        for t_level in target_class_list :\n", "            t_level_count = self . data [ self . data [ self . target ] == t_level ].shape [0]\n", "            for f_level in feature_class_list :\n", "                counter =0\n", "                for i in range ( total_rows ) :\n", "                    if ( self . data . loc [i , feature ] == f_level ) and ( self . data .loc [i , self . target ] == t_level ) :\n", "                        counter +=1\n", "                cp_smoother = ( counter + k ) /( t_level_count +( k * f_level_count ))\n", "                cond_prob_list . append (( feature , f_level , t_level , round (cp_smoother ,3) ) )\n", "        return cond_prob_list\n", "    \n", "    def count_all_prob ( self , k = None ) :\n", "        X=self.data.drop([self.target],axis=1)\n", "        if k!=None:\n", "            for feature in X.columns :\n", "                cond_list = self . cond_prob_LPSmoother(feature,k)\n", "                self.prob_all = self . prob_all + cond_list\n", "        else:\n", "            for feature in X.columns :\n", "                cond_list = self . cond_prob(feature)\n", "                self.prob_all = self . prob_all + cond_list\n", "            \n", "        return self.prob_all\n", "    def fit (self,smoothing='LPS',k=None) :\n", "        self.target_prob()\n", "        if smoothing == 'LPS' and k!=None:\n", "            self . count_all_prob (k)\n", "        else:\n", "            self . count_all_prob ()\n", "        return None\n", "    def pred_score ( self , query ) :\n", "        num_of_arg=self.data.shape[1]-1\n", "        query_length=len(query)\n", "        prob_dict=dict()\n", "        prob_prod=1\n", "        feature_list=self.data.columns\n", "        if query_length != num_of_arg :\n", "            print ('Query required ', num_of_arg ,' number of arguments')\n", "            print ('Data set column ', self.data.columns )\n", "        else :\n", "            i =0\n", "            ci =0\n", "            decided_bin= ''\n", "            query_copy = [i for i in query] \n", "            for item in query :\n", "                if type(item) != int and type(item) !=float:\n", "                    if item not in self . data . iloc [: , i ]. unique () :\n", "                        print ( item ,'is not in coulmn ', self . data . columns [ i ])\n", "                    i +=1\n", "                else:\n", "                    if self.bins[ci][0] <= item <= self.bins[ci][1]:\n", "                        decided_bin ='bin1'\n", "                    elif self.bins[ci][1] <= item <= self.bins[ci][2]:\n", "                        decided_bin ='bin2'\n", "                    elif self.bins[ci][2] <= item <= self.bins[ci][3]:\n", "                        decided_bin ='bin3'\n", "                    else:\n", "                        decided_bin ='bin4'\n", "                        \n", "                    query_copy[i] = decided_bin\n", "                    i+=1\n", "                    ci+=1   \n", "    \n", "            for t_level in self . data [ self . target ]. unique () :\n", "                for cnt in range ( query_length ) :\n", "                    for item in self . prob_all :\n", "                        if item [0]== feature_list [cnt] and item [1]== query_copy [cnt] and item [2]== t_level :\n", "                            prob_prod = prob_prod * item [3]\n", "                prob_dict [ t_level ]= round ( prob_prod * self . tprob_dict [ t_level] ,4)\n", "                prob_prod = 1\n", "        return prob_dict\n", "    \n", "    def pred ( self , query ) :\n", "        pr_dict = self . pred_score ( query )\n", "        return max( pr_dict , key = pr_dict . get )\n", "    \n", "    def get_prob_dict ( self ) :\n", "        print ('Target probabilities : ', self . tprob_dict )\n", "        print ('Conditional features Probabilities : ', self . prob_all )\n", "        return None\n", "    \n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[8]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Binning:\n", "    def __init__ ( self , df , features ) :\n", "        self . df = df\n", "        self . features = features\n", "        self.bins = list()\n", "    \n", "    \n", "    def binning_ranges(self,feature):\n", "        bin_ranges= []\n", "        col = df[feature]\n", "        col= col.sort_values(ascending=True)\n", "        col_values= [i for i in col]\n", "        bin_freq = col.shape[0]/4\n", "        n = 1\n", "        for i in range(5):\n", "            if i == 0:\n", "                bin_ranges.append(0)\n", "            elif i !=4:\n", "                avg = (col_values[int(round(n*bin_freq-1))] + col_values[int(round(n*bin_freq))])/2\n", "                bin_ranges.append(avg)\n", "                n+=1\n", "            else:\n", "                avg = col_values[int(round(n*bin_freq-1))]\n", "                bin_ranges.append(avg)\n", "        return bin_ranges\n", "    \n", "    def make_bins(self,df,feature):\n", "        label_names = [\"bin1\", \"bin2\",\"bin3\",\"bin4\" ]\n", "        cut_points = self.binning_ranges(feature)\n", "        self.bins.append(cut_points)\n", "        self.df[feature+\" Binnig\"] = pd.cut(df[feature], cut_points, labels=label_names)\n", "        \n", "    def get_bins(self):\n", "        return self.bins\n", "       \n", "    def get_new_dataset(self):\n", "        for i in self.features:\n", "            self.make_bins(self.df,i)\n", "        self.df =self.df.drop(self.features,axis=1)\n", "    \n", "        return self.df\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[11]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "data = pd . read_csv ('LoanApplication_cont.csv', sep =',')\n", "df = pd . DataFrame ( data )\n", "binning = Binning(df,['AccountBalance','LoanAmount'])\n", "df = binning.get_new_dataset()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# without smoothing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[12]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.drop(['ID'],axis=1)\n", "nbc = NBClassifier ( df ,'Fraud',binning.get_bins())\n", "nbc . fit ()\n", "query = ['paid','guarantor','free',759.07,8000]\n", "nbc . pred_score ( query )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[13]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nbc.pred(query)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[14]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nbc.get_prob_dict()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# With Smoothing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[15]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nbc = NBClassifier ( df ,'Fraud',binning.get_bins())\n", "nbc . fit (smoothing ='LPS',k =3)\n", "query = ['paid','guarantor','free',759.07,8000]\n", "nbc . pred_score ( query )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[16]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nbc.pred(query)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[17]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nbc.get_prob_dict()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}